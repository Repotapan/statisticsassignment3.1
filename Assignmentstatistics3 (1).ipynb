{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a4af39-4028-46a2-b2a3-0873c2243e50",
   "metadata": {},
   "source": [
    "Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with\n",
    "an example?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e49ccc-7364-46c0-9c5e-d8c5e7d32bed",
   "metadata": {},
   "source": [
    "The Probability Mass Function (PMF) and Probability Density Function (PDF) are two important concepts in probability theory and statistics that describe the probability distribution of a random variable.\n",
    "\n",
    "A Probability Mass Function (PMF) is a function that maps every possible value of a discrete random variable to its probability. It gives the probability of a specific outcome in a discrete probability distribution. In other words, a PMF describes the relative likelihood of each possible outcome of a discrete random variable. The PMF is often denoted as P(X=x), where X is the random variable and x is the value of the random variable.\n",
    "\n",
    "For example, suppose we have a fair six-sided die. The PMF of this die would be:\n",
    "P(X=1) = 1/6\n",
    "P(X=2) = 1/6\n",
    "P(X=3) = 1/6\n",
    "P(X=4) = 1/6\n",
    "P(X=5) = 1/6\n",
    "P(X=6) = 1/6\n",
    "\n",
    "Here, X is the random variable representing the number obtained from rolling the die, and the PMF shows that the probability of rolling each number is 1/6.\n",
    "\n",
    "On the other hand, a Probability Density Function (PDF) is a function that describes the probability distribution of a continuous random variable. The PDF gives the relative likelihood of each possible value of a continuous random variable, but unlike the PMF, it does not give the probability of any specific value. Instead, the area under the curve of the PDF between two points gives the probability of the random variable taking a value within that range. The PDF is often denoted as f(X), where X is the random variable.\n",
    "\n",
    "For example, suppose we have a continuous random variable X that follows a normal distribution with a mean of 0 and a standard deviation of 1. The PDF of X would be:\n",
    "f(X) = (1/√(2π))e^(-X^2/2)\n",
    "\n",
    "Here, the PDF describes the relative likelihood of each possible value of X, but it does not give the probability of any specific value. The probability of X taking a value between two points a and b can be calculated by integrating the PDF between a and b:\n",
    "\n",
    "P(a ≤ X ≤ b) = ∫a^b f(X) dX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d881018-6554-411f-9da6-776351831ba7",
   "metadata": {},
   "source": [
    "Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51affda-ed3b-419a-bdc0-d7607f815be7",
   "metadata": {},
   "source": [
    "The Cumulative Density Function (CDF) is a function that describes the probability that a continuous random variable takes on a value less than or equal to a given value. In other words, the CDF gives the cumulative distribution of the random variable.\n",
    "\n",
    "The CDF is often denoted as F(X), where X is the random variable. Mathematically, the CDF is defined as:\n",
    "\n",
    "F(X) = P(X ≤ x)\n",
    "\n",
    "In other words, the CDF gives the probability that the random variable X is less than or equal to a given value x. The CDF is defined for both discrete and continuous random variables.\n",
    "\n",
    "For example, let's consider a continuous random variable X that follows a normal distribution with a mean of 0 and a standard deviation of 1. The CDF of X would be:\n",
    "\n",
    "F(X) = Φ(X) = ∫(-∞)^X f(t) dt\n",
    "\n",
    "Here, Φ(X) is the standard normal cumulative distribution function, f(t) is the PDF of the standard normal distribution, and X is the value of the random variable.\n",
    "\n",
    "The CDF is used for various purposes, such as:\n",
    "\n",
    "Finding the probability of a random variable taking a value less than or equal to a specific value.\n",
    "Calculating the expected value and variance of a random variable.\n",
    "Evaluating statistical hypotheses using hypothesis tests.\n",
    "Generating random samples from a probability distribution using the inverse CDF method.\n",
    "Overall, the CDF is an important tool in probability theory and statistics that allows us to understand and analyze the behavior of random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccb997a-01e8-4da7-86b2-8d07f27bf98e",
   "metadata": {},
   "source": [
    "Q3: What are some examples of situations where the normal distribution might be used as a model?\n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45314cc9-3b8f-4a41-af74-8b93e7c12d87",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution, is a probability distribution that is commonly used as a model in various fields such as statistics, economics, engineering, and natural sciences. It is a continuous distribution that has a bell-shaped curve and is characterized by two parameters: the mean (μ) and the standard deviation (σ).\n",
    "\n",
    "Some examples of situations where the normal distribution might be used as a model include:\n",
    "\n",
    "Heights and weights of people: In many populations, height and weight tend to follow a normal distribution.\n",
    "\n",
    "Test scores: The scores of standardized tests, such as the SAT or GRE, often follow a normal distribution.\n",
    "\n",
    "IQ scores: IQ scores also tend to follow a normal distribution.\n",
    "\n",
    "Error distributions: In many statistical models, the error term is assumed to follow a normal distribution.\n",
    "\n",
    "The parameters of the normal distribution, namely the mean and standard deviation, determine the shape of the distribution. The mean represents the center of the distribution and the standard deviation represents the spread or variability of the distribution.\n",
    "\n",
    "If the mean is zero and the standard deviation is one, the distribution is called a standard normal distribution, and it has a bell-shaped curve that is symmetric around the mean. As the mean increases or decreases, the entire distribution is shifted to the right or left, respectively. As the standard deviation increases or decreases, the distribution becomes more spread out or more concentrated around the mean, respectively.\n",
    "\n",
    "Overall, the normal distribution is a versatile and widely used distribution that allows us to model and analyze a wide range of phenomena, making it an important tool in statistics and data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26280e97-c77e-4408-aae5-f44292e9d39f",
   "metadata": {},
   "source": [
    "The normal distribution is one of the most important probability distributions in statistics and data analysis. Its importance stems from its properties, which make it a useful tool for modeling and analyzing a wide range of phenomena.\n",
    "\n",
    "Some of the key reasons for the importance of the normal distribution are:\n",
    "\n",
    "Central Limit Theorem: The normal distribution is a key component of the Central Limit Theorem, which states that the sample mean of a large number of independent and identically distributed random variables will follow a normal distribution, regardless of the underlying distribution of the variables themselves. This makes the normal distribution a powerful tool for statistical inference and hypothesis testing.\n",
    "\n",
    "Real-life applications: Many natural and social phenomena can be approximated by a normal distribution. This makes it a useful model for analyzing real-world data in fields such as finance, engineering, physics, biology, and economics.\n",
    "\n",
    "Ease of use: The normal distribution is easy to work with mathematically and computationally, making it a popular choice for modeling and analysis.\n",
    "\n",
    "Some examples of real-life phenomena that can be modeled using a normal distribution include:\n",
    "\n",
    "Heights and weights of people: In many populations, height and weight tend to follow a normal distribution.\n",
    "\n",
    "Test scores: The scores of standardized tests, such as the SAT or GRE, often follow a normal distribution.\n",
    "\n",
    "IQ scores: IQ scores also tend to follow a normal distribution.\n",
    "\n",
    "Stock prices: Daily changes in stock prices are often modeled using a normal distribution.\n",
    "\n",
    "Measurement errors: Errors in measurement, such as errors in experimental measurements or errors in the measurement of physical quantities, can be modeled using a normal distribution.\n",
    "\n",
    "Overall, the normal distribution is an important and widely used tool in statistics and data analysis, and its properties make it a useful model for analyzing a wide range of real-world phenomena."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5c68e2-2b65-4446-b0cc-3e2ea381f1e0",
   "metadata": {},
   "source": [
    "Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli\n",
    "Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d3f835-8ca9-4f9e-90bc-64cbdad53d5e",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is a discrete probability distribution that models a single trial of an experiment that has only two possible outcomes: success and failure. It is named after Swiss mathematician Jacob Bernoulli, who studied it in the 17th century.\n",
    "\n",
    "The Bernoulli distribution is characterized by a single parameter p, which represents the probability of success in a single trial. The probability mass function (PMF) of the Bernoulli distribution is:\n",
    "\n",
    "P(X=x) = p^x(1-p)^(1-x) for x=0,1\n",
    "\n",
    "where X is the random variable that represents the outcome of a single trial, and x can take on the values 0 or 1, representing failure and success, respectively.\n",
    "\n",
    "An example of a situation where the Bernoulli distribution might be used is flipping a coin, where the two possible outcomes are heads and tails. We can define success as getting heads and failure as getting tails, and model the probability of getting heads in a single flip using the Bernoulli distribution.\n",
    "\n",
    "The main difference between the Bernoulli distribution and the Binomial distribution is that the Bernoulli distribution models a single trial of an experiment with two possible outcomes, while the Binomial distribution models the number of successes in a fixed number of independent Bernoulli trials.\n",
    "\n",
    "The Binomial distribution is characterized by two parameters: n and p, where n represents the number of independent trials and p represents the probability of success in a single trial. The probability mass function (PMF) of the Binomial distribution is:\n",
    "\n",
    "P(X=x) = (n choose x) * p^x * (1-p)^(n-x) for x=0,1,2,...,n\n",
    "\n",
    "where X is the random variable that represents the number of successes in n independent Bernoulli trials.\n",
    "\n",
    "In other words, the Binomial distribution is the sum of n independent Bernoulli trials. An example of a situation where the Binomial distribution might be used is counting the number of heads in a fixed number of coin flips."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4511eb-60da-4c19-8a36-7159d32b3e6c",
   "metadata": {},
   "source": [
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater\n",
    "than 60? Use the appropriate formula and show your calculations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b23189-a164-402c-8261-4098c4523f51",
   "metadata": {},
   "source": [
    "Here u(mean)=50\n",
    "x = 60\n",
    "std=10\n",
    "z score=x-u/std=60-50/10=1\n",
    "According to z score table,the area under the curve=0.8413\n",
    "The area under the curve > 60 is 1-0.8413=0.1587(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216b4523-8840-4f86-83de-e34b91522a13",
   "metadata": {},
   "source": [
    "Q7: Explain uniform Distribution with an example?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ddc1b0-4d82-4db8-9c0b-83b1df94cce6",
   "metadata": {},
   "source": [
    "The uniform distribution is a continuous probability distribution that models a situation where all outcomes within a given interval are equally likely. In other words, every value within the interval has the same probability of occurring.\n",
    "\n",
    "The probability density function (PDF) of a uniform distribution on the interval [a,b] is given by:\n",
    "\n",
    "f(x) = 1/(b-a) for a <= x <= b\n",
    "f(x) = 0 otherwise\n",
    "\n",
    "where x is a random variable that takes on values within the interval [a,b], and f(x) represents the probability density at x.\n",
    "\n",
    "An example of a situation where the uniform distribution might be used is rolling a fair die. In this case, the possible outcomes are the integers 1 through 6, and each outcome is equally likely. We can model the probability of rolling a particular value using a uniform distribution on the interval [1,6].\n",
    "\n",
    "Another example of a situation where the uniform distribution might be used is selecting a random number between 0 and 1. In this case, any number between 0 and 1 is equally likely to be selected, and we can model the probability distribution of the selected number using a uniform distribution on the interval [0,1].\n",
    "\n",
    "In general, the uniform distribution is a useful model for situations where all outcomes within a given interval are equally likely, and where we have no reason to believe that certain outcomes are more likely than others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75f3c92-1660-4592-b5c4-52526bc8fb38",
   "metadata": {},
   "source": [
    "Q8: What is the z score? State the importance of the z score?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4ac37e-fe2f-4080-b5d1-485041edce0e",
   "metadata": {},
   "source": [
    "The z-score is a statistical measure that represents the number of standard deviations an observation or data point is above or below the mean of a dataset. It is calculated by subtracting the mean of the dataset from the observed value and then dividing the difference by the standard deviation of the dataset.\n",
    "\n",
    "The formula for calculating the z-score is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where x is the observed value, μ is the mean of the dataset, and σ is the standard deviation of the dataset.\n",
    "\n",
    "The z-score is important because it standardizes data and allows for comparisons between different datasets. By converting raw data into standardized units, researchers and analysts can easily compare observations from different datasets that may have different units of measurement or scales. The z-score is also used in hypothesis testing and determining confidence intervals, as well as identifying outliers in a dataset. Additionally, the z-score is used in many other statistical analyses, such as regression analysis, factor analysis, and cluster analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6722f17e-74b6-46eb-af80-b35c081b4d7a",
   "metadata": {},
   "source": [
    "Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc566f97-8961-496f-a53b-f0a43e4a4b65",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that states that as the sample size of a random variable increases, the distribution of the sample means will approach a normal distribution, regardless of the underlying distribution of the population from which the samples are drawn.\n",
    "\n",
    "In other words, if we take repeated samples of the same size from a population, the distribution of sample means will become increasingly normal as the sample size increases, even if the underlying population is not normally distributed. The CLT applies to any distribution with a finite variance, including uniform, exponential, and even highly skewed distributions.\n",
    "\n",
    "The significance of the Central Limit Theorem is that it provides a basis for many statistical inference methods, such as hypothesis testing and confidence interval estimation. It allows us to make reliable statistical inferences about a population based on a relatively small sample size. In addition, it enables us to use parametric tests, which require the assumption of normality, even if the underlying population distribution is not normal, as long as the sample size is large enough. This is important because normal distribution is well-understood and widely studied in statistics, making many statistical methods easier to apply in practice. Finally, the Central Limit Theorem is also used in quality control and process improvement, where it helps to identify sources of variation and determine whether a process is within specification limits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba158dc-3c67-451d-83a7-c619837be4b4",
   "metadata": {},
   "source": [
    "Q10: State the assumptions of the Central Limit Theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ae28b6-231b-4b3f-ae90-cec87c7b878e",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) makes several assumptions to hold true:\n",
    "\n",
    "The samples are independent: Each sample is drawn randomly and independently from the population, and the sample size is small enough so that one sample does not affect another.\n",
    "\n",
    "The population is identically distributed: All the samples are drawn from a single population with the same distribution, regardless of the sample size.\n",
    "\n",
    "The population has a finite variance: The population from which the samples are drawn has a finite variance, which means that the spread of the population is not infinite.\n",
    "\n",
    "The sample size is sufficiently large: The sample size is large enough so that the sample means follow a normal distribution, regardless of the underlying population distribution.\n",
    "\n",
    "It is important to note that violation of any of these assumptions may lead to the failure of the Central Limit Theorem to hold. In particular, the sample size plays a crucial role in the validity of the Central Limit Theorem. If the sample size is too small, the distribution of the sample means may not approximate a normal distribution, even if the other assumptions are satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef7fc8-5b57-4c8f-a2a5-e88aa37ce35b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
